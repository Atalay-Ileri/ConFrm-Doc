\documentclass[onecolumn]{paper}
\usepackage{tabularx}
\usepackage{color}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}

\title{ConFrm: Confidentiality Framework for Crash Safe Storage Systems}
\author{Atalay Mert Ileri \and Frans Kaashoek \and Nickolai Zeldovich}
\begin{document}
\maketitle

\section{Abstract}

\section{Introduction}

%%% 
% Motivate this problem.
% Maybe refer to DiskSec couldn't do it.
% Protection from adverserial implementation.
% Important point of view.
% Make security similar to FC.
%%%

\section{Related Work}

\section {Definitions}

\section{Confidentiality}
	\subsection{Description and Definitions}

\section{Problems}
        \subsection{Leakage via hashing}

%{\color{red}
% Motivate this problem.
% Maybe refer to DiskSec couldn't do it.
% Protection from adverserial implementation.
% Important point of view.
% Make security similar to FC.
%}

	\paragraph*{Malicious Example}
	\begin{verbatim}
		hash <- hash_block b
		if (hash =/= 0) then
			write given_addr b
		else
			write malicious_addr b
	\end{verbatim}

	\paragraph*{Okay example}
	\begin{verbatim}
		hash <- hash_block b
		if (hash =/= 0) then
			write given_addr b
	\end{verbatim}

	A primitive can be used maliciously.\\
	There isn’t a way to limit how it’s used.\\
	Language level safety techniques are not usable if potentially exploitable primitives are in the language.

	\subsection{Leakage via nondeterminism frequencies}	
	Standard nondeterministic noninterference definition allows leakage via relative frequency of outcomes.
	\paragraph{Nondeterministic Noninterference:}
	
	\begin{verbatim}
		forall p s1 s2 s1’ v,
		R s1 s2 ->
		exec s1 p s1’ v ->
		
		exists s2’,
		exec s2 p s2’ v /\
		R s1’ s2’.
	\end{verbatim} 
	
	
	
	\paragraph*{Leaky example}
	\begin{verbatim}
		should_leak <- get_random_bit()
		if (should_leak = 1)
			return secret_bit
		else
			return get_random_bit()
	\end{verbatim}
	
	This code leaks the secret bit 50\% of the time and outputs a random bit 50\% of the time.
	Satisfies above definition but the secret bit can be determined via the observed frequency.
	
	\begin{tabular}{| c | c | c |}
		\hline
		Secret bit & Output 0 \% & Output 1 \% \\
		\hline
		0 &	75\% & 25\% \\
		\hline
		1 &	25\% & 75\% \\
		\hline
		\end{tabular}
	
	\subsection{Modularity}
        \newpage

\section{ConFrm Framework}
	\subsection{Addressing hash leakage}
	Need to have a way to take advantage of the fact that they are used safely.
	Our solution is abstracting the leaky primitive away.
	Abstract language won’t have a leaky primitive anymore so language level techniques can be used.

	\subsection{Addressing frequency leakage}
	Our suggested solution, parameterize the execution with a nondeterminism oracle, so that execution is deterministic w.r.t. an oracle.
		
		\subsubsection{Externalizing the nondeterminism via oracles}
			%%Add an example here to show the difference between old and new semantics
			\paragraph{Deterministic w.r.t. an oracle:}
			\begin{verbatim}
				forall oracle p s s1 v1 s2 v2,
				exec oracle s p s1 v1 ->
				exec oracle s p s2 v2 ->
				s1  = s2 /\ v1 = v2.
			\end{verbatim}
	
			\paragraph{Relativized Noninterference:}
			\begin{verbatim}
				forall oracle p s1 s2 s1’ v,
				R s1 s2 ->
				exec oracle s1 p s1’ v ->
				
				exists s2’,
				exec oracle s2 p s2’ v /\
				R s1’ s2’.
			\end{verbatim}
						
			The malicious example doesn’t satisfy relativized noninterference. For the oracle [should\_leak = 1], there is no corresponding execution from the opposite secret bit value.
			
			\subsubsection{Data Noninterference}
			
			Our definition should cover both leaking from others to current user and from current user to ours. So two components are\\
			
			1)FS doesn't leak from current user's files to others' files.
			
			2)FS doesn't leak from others' files to current user's files.\\
			
			
			(1) can be established with:
			
			- Start with two states where others' files are the same but current user's files are different.
			
			- Run same syscall with same parameters on both.\\ 
			(also two Write/Extend syscalls with different block contents 
			e.g. "Write inum offset block1" vs. "Write inum offset block2")
			
			- Others' files are the same after syscall finishes (or crashes and recovers).\\
			
			(2) can be established with:
			
			- Start with two states where others' files are different but current user's files are the same.
			
			- Run same syscall with same parameters on both
			
			- Current user's files and syscall return values are the same after syscall finishes (or crashes and recovers).\\
			
			For change\_owner, our NI statement (1) will exclude the file that is being operated on. 
			Absence of leakage into the operated file will be covered by functional correctness of change\_owner.
			(i.e. It will state that contents of the file is the same before and after change\_owner)\\
			
			
			{\bf Equivalence Relation}
			
			To cover all of the above, our equivalence relation between two file disks will be parameterized by a user and an option inum.
			It will informally state that:\\
			
			For a user u, a potentially excluded file ex, two file disks d1 and d2, 
			d1 and d2 are equivalent if
			
			1) d1 and d2 have same file handles (i.e. used inums are the same), and\\
			
			$\forall\ inum,\ d1[inum] \ne None \leftrightarrow d2[inum] \ne None$\\
			
			
			2) For any file in d1, corresponding file in d2 have the same owner and the same length. More formally:\\
			
			$\forall\ handle\ inum,$
			
			$d1[inum].owner = d2[inum].owner\ \wedge$
			 
			$length (d1[inum].blocks) = length (d2[inum].blocks)$\\
			
			3)  Any non-excluded file that is owned by u is the same in both disks. \\ 
			
			$\forall\ handle\ inum,$
			 
			$inum \ne ex \rightarrow$
			
			$d1[inum].owner = u \rightarrow$
			
			$d1[inum] = d2[inum]$\\
			
			
			{\bf Semi-Formal Noninterference Definitions}
			
			{\bf Case 1}\\
			
			{\bf Non-change\_owner syscalls}

			$\forall\ d_1\ d_2\ u\ u'\ syscall\ d_1'\ v_1,$
			
			$u \ne u' \rightarrow$
			
			$eqv\ u'\ None\ d_1\ d_2 \rightarrow$
			
			$exec\ u\ d_1\ syscall\ (d_1', v_1) \rightarrow$
			
			$\exists\ d_2'\ v_2,$
			
			$exec\ u\ d_2\ syscall\ (d_2', v_2)\ \wedge$
			
			$eqv\ u'\ None\ d_1'\ d_2'$\\
			
			
			{\bf change\_owner special case}
			
			$\forall\ d_1\ d_2\ u\ u'\ inum\ new\_owner\ d_1'\ v_1,$
			
			$eqv\ u'\ (Some\ inum)\ d_1\ d_2 \rightarrow$
			
			$exec\ u\ d_1\ (change\_owner\ inum\ new\_owner)\ (d_1', v_1) \rightarrow$
			
			$\exists\ d_2'\ v_2,$
			
			$exec\ u\ d_2\ (change\_owner\ inum\ new\_owner)\ (d_2', v_2)\ \wedge$
			
			$eqv\ u'\ (Some\ inum)\ d_1'\ d_2'$\\
			
			
			{\bf Write/Extend special case}
			
			$\forall\ d_1\ d_2\ u\ u'\ inum\ off\ b_1\ b_2\ d_1'\ v_1,$
			
			$eqv\ u'\ (Some\ inum)\ d_1\ d_2 \rightarrow$
			
			$exec\ u\ d_1\ (Write\ inum\ off\ b_1)\ (d_1', v_1) \rightarrow$
			
			$\exists\ d_2'\ v_2,$
			
			$exec\ u\ d_2\ (Write\ inum\ off\ b_2)\ (d_2', v_2)\ \wedge$
			
			$eqv\ u'\ (Some\ inum)\ d_1'\ d_2'$\\
			
			%It covers confidentiality of chained writes
			
			{\bf Case 2}
			 
			 $\forall\ d_1\ d_2\ u\ syscall\ d_1'\ v_1,$
			 
			 $eqv\ u\ None\ d_1\ d_2 \rightarrow$
			 
			 $exec\ u\ d_1\ syscall\ (d_1', v_1) \rightarrow$
			 
			 $\exists\ d_2'\ v_2,$
			 
			 $exec\ u\ d_2\ syscall\ (d_2', v_2)\ \wedge$
			 
			 $eqv\ u\ None\ d_1'\ d_2'\ \wedge$
			 
			 $v_1 = v_2$\\
			
			
			{\bf Functional correctness for change\_owner}\\
			forall d1 u inum new\_owner d1',
			exec u d1 (change\_owner inum new\_owner) (d1', Some tt) ->
			d1'[inum] = {| owner:= new\_owner; blocks:=d1[inum].blocks |}.\\
			
			
			
			{\bf Merging into a single NI statement}
			Since (1) and (2) are very similar, we can merge both of them into a single definition that captures both:\\
			
			$\forall\ d_1\ d_2\ u\ u'\ syscall\ d_1'\ v_1,$
			
			$eqv\ u'\ None\ d_1\ d_2 \rightarrow$
			
			$exec\ u\ d_1\ syscall\ (d_1', v_1) \rightarrow$
			
			$\exists\ d_2'\ v_2,$
			
			$exec\ u\ d_2\ syscall\ (d_2', v_2)\ \wedge$
			
			$eqv\ u'\ None\ d_1'\ d_2'\ \wedge$
			
			$(u = u' \rightarrow v_1 = v_2)$\\
			
			{\bf Why do we need special change\_owner definition?}
			In general definition, if u' = new\_owner, contents of the file we are operating on may not be identical in equivalent states. 
			Because of this, resulting states may not be equivalent for the new owner. 
			This fact requires us to use a sligthly weaker variant of the equivalence for change\_owner.
			
			Weaker variant does not state anything about the contents of the operated file.
			Proof of contents not changing comes from the functional correctness.\\
			
			
			{\bf Why do we need special Write/Extend definitions?}\\
			Here is an implementation of extend syscall that satisfies the generic definition but leaks the data in a future call.
			
			\begin{verbatim}
				extend (inum, block){
					append_to_file(stash_file, block)
					append_to_file(inum, block)
				}
			\end{verbatim}
			
			
			if two states were equivalent before, they will be still equivalent after if  you extend with the same block. Coupled with an adversarial Read implementation, this can cause leakage of private data although satisfying the generic definition.
			
			However, this implementation will not satisfy the special case theorem because different values will break equivalence between stash files.\\
			
			{\bf What if an implementation uses a hidden underlying layer primitive (like a stash block that is not part of any file) to stash data?}\\
			
			In that case, two implementation states that differ only in stash block will refine to the same abstract state (which is equivalent to itself for every user). 
			
			If that is the case, then a read implementation that would return stash\_block's content would return two different values from the same state. This would prevent both NI and Simulation obligations to be proven correct.\\
			
			{\bf TLDR}\\
			We need to prove following 3 NI statements and one FC statement:
			
			For all syscalls except change\_owner,
			
			forall d1 d2 u u' syscall d1' v1,
			eqv u' None d1 d2 ->
			exec u d1 syscall (d1', v1) ->
			exists d2' v2,
			exec u d2 syscall (d2', v2) /\
			eqv u' None d1' d2' /\
			(u = u' -> v1 = v2).
			
			For Write (and Extend) special case:
			
			// Document reason why it is this way
			// Create examples
			// Think if it needs to be general or simplified
			
			forall d1 d2 u u' inum off b1 b2 d1' v1,
			eqv u' (Some inum) d1 d2 ->
			exec u d1 (Write inum off b1) (d1', v1) ->
			exists d2' v2,
			exec u d2 (Write inum off b2) (d2', v2) /\
			eqv u' (Some inum) d1' d2'.
			
			
			
			Do we need generality?
			?????
			
			For change\_owner:
			
			forall d1 d2 u u' inum new\_owner d1' v1,
			eqv u' (Some inum) d1 d2 ->
			exec u d1 (change\_owner inum new\_owner) (d1', v1) ->
			exists d2' v2,
			exec u d2 (change\_owner inum new\_owner) (d2', v2) /\
			eqv u' (Some inum) d1' d2' /\
			(u = u' -> v1 = v2).	
			
			
			
			
			Functional Correctness:
			forall d1 u inum new\_owner d1',
			exec u d1 (change\_owner inum new\_owner) (d1', Some tt) ->
			d1'[inum] = {| owner:= new\_owner; blocks:=d1[inum].blocks |}.
			
			
			
		\subsubsection{Generalizing simulations to oracles}

	\subsection{Compositionality}
		\subsubsection{Layer system}
		Layer system allows users to define languages as well as combine two languages into a single one, allowing decoupling of unrelated parts without loss of functionality.
		Its main building block is a core.\\ 
		
		{\bf Cores}
		
		Cores are the main component of the layer system. They are what a developer defines to create a new layer. They consist of four main parts: tokens, state, operations and execution semantics. Developers have total freedom in defining cores. Framework itself treats cores opaquely.
		
		\paragraph{Tokens}
		Tokens are the structure that provides nondeterminism to the system. A token provides all required nondeterminism for a single step of execution. A token can be as simple as a directive to continue execution or crash at that point or something more complex like a new encryption key, a free block number or even a list of tokens for other cores.
		
		\paragraph{Operations}
		These are the “opcodes” of the language. (e.g. Read and Write for a disk).
		
		
		\paragraph{Execution Semantics}
		Describes execution semantics of each operation. Must be deterministic with respect to a given token.\\
		
		{\bf Languages}
		
		A language is a structure that extends a core with a stateful computation monad. It has tokens, state, program, normal and recovery execution semantics. All of these are generated automatically from a given core by the framework.
		
		\paragraph{Recovery Semantics}
		Recovery semantics takes a list of oracles, a program, a recovery program and a list of reboot state functions. It is deterministic given a particular oracle list and a reboot state function list.
		
		{\bf //TODO: example semantics here}\\
				
		{\bf Horizontal Composition}
		
		Framework allows developers to automatically combine two cores into a new core. This allows developers to introduce new state and functionality to their system at appropriate abstraction levels without modifying the rest of the system.
		
		Given two cores, framework creates a new core by “tagging” the tokens and operations either first or second (i.e. uses a sum monad). New execution semantics are a combination of original semantics, and the new state is the pair of original states. 
		
		Framework also provides two functions to ‘lift’ existing programs from languages derived from the two cores to programs in a language derived from their composition. This allows using already existing programs in input languages.		
		
		\subsubsection{Noninterference transfer}
		
		
		
		{\bf Simulation System}
		
		
		{\bf Core-to-Language Refinement}
		Core-to-language refinement (core refinement for short) is a refinement between the core of an abstraction and the language of an implementation. It has 4 components: a compile function, a state refinement relation, a token refinement relation and a proof that compiled operations preserve refinement. 
		
		\paragraph{Compile Function}
		This is a function from an abstract operation to an implementation program.
		
		\paragraph{State Refinement Relation}
		This is the relation that relates an abstract state to an implementation state. It could be a many-to-many relation.
		
		\paragraph{Token Refinement Relation}
		This is a refinement relation between a token of abstraction and an oracle of implementation. It also depends on an abstract operation and an implementation state.The operation is needed because not all tokens are valid for all operations. Implementation state is used to inject some information into a token to hide some implementation details (i.e. an empty block number n to create a NewBlockNum token). 
		
		\paragraph{Refinement Preservation Proof}
		To complete the refinement, a proof of that any valid execution of a compiled operation should preserve the refinement should be supplied. This theorem ensures that implementation execution cannot result in a “rogue state” which does not correspond to an abstract state.\\
		
		{\bf Language-to-Language Refinement}
		Language-to-language refinement (refinement for short) is a refinement between the language of an abstraction and the language of an implementation.
		
		Framework provides the machinery to automatically generate a refinement from a given core refinement.
		
		To facilitate that, it extends the compile function for return and bind. 
		Also defines an abstract oracle to implementation oracle refinement, based on the token refinement of core refinement. 
		
		Since the state of a core and its language are the same, state refinement relation stays the same.\\
		
		
		{\bf Strong Simulation}\\
		
		
		{\bf Self Simulation}
		
		This is the general definition that captures noninterference property.
		It is parameterized over 
		two programs p1 and p2, 
		a recovery program
		a list of reboot state functions
		a state validity predicate
		a simulation relation.
		
		It states that an execution (with recovery) of p1 from a valid state implies the existence of an execution (with recovery) of p2 from another valid state that is related to the first one via simulation. Furthermore, return values of these two executions are the same, resulting states are valid and related to each other.
		
		
		\subsubsection{Bisimulation to Simulation via Determinism}
		
		

	\subsection{Crash Support}
		\subsubsection{Crash semantics}
		Crash semantics of a language recursively defined over a program and a recovery program. It models two possibilities of overall execution can take:
		Either original program finishes successfully, or program crashes then recovers after certain number of attempts by running recovery program.  
		Variable number of attempts are required to model the fact that system can crash in the middle of a recovery.
		
		{\bf //TODO: Figure here}
		
		Since there may be multiple crashes until a successful recovery, semantics uses a list of oracles. Whenever a crash happens, next oracle in the list is used to run the next recovery program.
		
		\subsubsection{Reboot State Functions}
		Depending on a type of storage that is used, state of a storage after a crash and reboot may not be the same with its state just before the crash.
		For example, a disk may lose some writes, a memory loses its entire content etc.
		
		We model this phenomenon with what we call a reboot state function. A reboot state function is a function such that, given a state just before a crash, gives the state after a crash and reboot. It is true that there may be possible after reboot states that corresponds to a single before crash state. In our framework, each of those possibilities are represented via a different reboot state function.
		
		{\bf //TODO: Disk RSF example here}
		
		Reboot state functions are part of the trusted definitions provided by a developer.
		
		\subsubsection{Crash refinement}
\newpage
\section{Framework in Action: ConFS}
	\subsection{Design and Specs}
		\subsubsection{Layers}
			\begin{tabularx}{\linewidth}{|L|L|L|L|}
				\hline
				Layer Name &
				Operations &
				State &
				Type \\
				\hline
				Disk &
				Read, Write, Sync &
				A $\rightarrow$ (V * list V) &
				Basic \\
				\hline
				Cache &
				Read, Write, Flush &
				A $\rightarrow$ option V &
				Basic \\
				\hline
				Crypto &
				Hash, GetKey, Encrypt, Decrypt &
				list key, 
				hash $\rightarrow$ option (hash, V) &
				Basic \\
				\hline
				Crypto Disk &
				Crypto ops + Disk ops &
				Crypto state + Disk state &
				Composed \\
				\hline
				Cached Disk &
				Cache ops + Crypto Disk ops &
				Cache state + Crypto Disk state &
				Composed \\
				\hline
				Logged Disk &
				Read, Write, Recover &
				A $\rightarrow$ V &
				Abstraction \\ 
				\hline
				Storage &
				Get, Put, Delete &
				option V &
				Basic \\
				\hline
				Transaction Cache &
				Storage ops + Logged Disk ops &
				Storage state + Logged Disk state &
				Composed \\
				\hline
				Transactional Disk &
				Start, Read, Write, Commit, Abort, Recover &
				mem A V , mem A V &
				Abstraction \\
				\hline
				Authentication &
				Auth &
				user &
				Basic \\
				\hline
				Authenticated Disk &
				Authentication ops + Transactional Disk ops &
				Authentication state + Transactional Disk state &
				Composed \\
				\hline
				File Disk &
				Read, Write, Extend, Set Owner, Create, Delete, Recover &
				mem A File &
				Abstraction \\
				\hline
			\end{tabularx}
	\subsection{Implementation}
		\subsubsection{Modules}
		\begin{tabularx}{\linewidth}{|L|L|L|L|L|}
		\hline
		Component & API & Used Implementation &	Used Layer & Abstracted Into \\
		\hline
		Batch Operations &
		read\_consecutive, write\_consecutive,
		write\_batch, hash\_all,
		encrypt\_all, decrypt\_all &
		& 
		Crypto Disk & 
		\\
		\hline
		Log &
		commit, recover &
		Batch Operations &
		Crypto Disk & 
		\\
		\hline
		Log Cache &
		read, 
		write, 
		recover &
		Log &
		Cached Disk &
		Logged Disk \\
		\hline
		Transaction &
		start, commit, abort, 
		read, write, recover &
		&
		Transaction Cache &
		Transactional Disk \\
		\hline
		Block Allocator &
		alloc, free, read, write &
		&
		Transactional Disk &
		\\
		\hline
		Inode &
		alloc, free, expand, change\_owner, get\_block\_number, get\_block\_numbers, get\_owner &
		Block Allocator &
		Transactional Disk &
		\\
		\hline
		File &
		read, write, extend, change\_owner, create, delete, recover &
		Block Allocator, Inode &
		Authenticated Disk &
		File Disk \\
		\hline
	\end{tabularx}

	\subsubsection{Hash collisions and encrypted log}
		Since our implementation is using checksum logging, leakage of raw data after a crash is possible due to hash collisions. Sequence of events that leads to a leakage in a simple log can be summarized as follows:
		
		1) Log contains $block_1$ with matching hash $hash(block_1)$ in the header.
		
		2) A syscall that writes $block_2$ is initiated.
		
		3) FS calculates, writes $hash(block_2)$ 
		
		  (and by chance $hash(block_1) = hash(block_2)$).
		  
		4) Crash happens, after reboot $block_2$ didn't make it to the disk but header did.
		
		5) $block_1$ is written in place of $block_2$.
		
		To prevent this leakage, we implemented an encrypted log where each transaction is encrypted with a fresh secret key before written to the log.
		Hash of the log is computed over the encrypted blocks. When log needs to be applied, FS decrypts the blocks before writing them to their permanent places.
		
		This implementation does not prevent hash collisions but it changes what is written back in step 5 to $decrypt(k_2, encrypt(k_1, block_1))$, which is independent of $block_1$ by standard cryptographic assumptions.
		
		\subsubsection{Unequal Probabilities After Crash and Encryption}
		
		Consider following scenario:
		
		1) There are two equivalent states: Both logs are empty but residual blocks are $b_1$ and $b_2$.
		
		2) User attempts to write $b_1$.
		
		3) Crash happens after write but before sync.
		
		4) After reboot, new header is persisted but the new block didn't.
		
		5) After recovery, one state has empty log, and other has a valid transaction.\\
		
		{\bf Why didn't we encounter this during proofs?}
		
		This dichotomy will manifest itself in refinement of abstract tokens.
		
		First state will require abstract token to be CrashAfter since transaction is committed after recovery.
		
		Second state will require abstract token to be CrashBefore since transaction is rolled back after recovery.
		
		This conflict would appear in the proof of two abstract tokens refined from two related states being the same.
		
		I didn't encounter this because I didn't do that proof yet. If I attempted, it probably wouldn't go through.\\
		
		{\bf How can we solve this?}\\
		What needs to be fixed is that, with the same reboot function, both states either should roll back or keep the transaction.
		Above requirement means that, there shouldn't be a case where newly written block to log is exactly equal to the already existing block.
		There are two ways to achieve this:\\
		
		1) Design a log that {\bf guarantees} that requirement.
		
		I did it back in the day but it was very complicated. I expect it to be practically infeasible to reason about that log. That is why we didn't pursue this. 
		Could be an interesting side project though.\\
		
		2) Design a log where this case is an {\bf exponentially unlikely} event. 
		This makes it reasonable to exclude such cases from our proofs.
		
		This is the approach we take with hash collisions and encryption achieves this.
		If we encrypt each transaction with a fresh key, above situation only happens when $encrypt(k_1, b_1) = encrypt (k_2, b_2)$ where $k_1 \ne k_2$. This is exponentially unlikely as far as I am aware.\\
		
		{\bf How can we capture this?}\\		
		We can't introduce an axiom that says 
		
		$\forall\ k_1\ k_2\ b_1\ b_2,\ k_1 \ne k_2 \rightarrow encrypt(k_1, b_1) \ne encrypt(k_2, b_2)$\\
		
		At first glance it looks fine because key and block are abstract types. 
		Therefore you can't construct an example where $k_1 \ne k_2\ \wedge\ encrypt(k_1, b_1) = encrypt(k_2, b_2)$ which would allow you to prove False.
		 
		Still, this isn't kosher because it makes our model not fit the world. There is no such encrypt function that satisfies the above axiom. Assuming it would make our proofs meaningless, since they are not about our world anymore.\\
		
		Another way to achieve it is how we achieved it with hashing. Keep a record of each encryption done, when you see a collision like above, let program get stuck. This is the implementation I had before, which I scrapped recently. 
		
		This was also the reason why our GetKey was weird. We needed to know that there won't be a collision when we encrypt our data with the generated key. I could be able to get rid of that weirdness thanks to we moving to simulations from bisimulations.
		Bisimulations required total correctness, simulations require partial correctness.\\
		
		Although above approach plays nice with 95\% of the project, it has a problem with write/extend special case NI proofs' transfer.
		One requirements of the transfer lemma for spacial case is "if $s_1$ and $s_2$ are equivalent states and you can run $write(a, b_1)$ from $s_1$, then you can run $write(a, b_2)$ from $s_2$ with the same oracle."
		
		To show that you can run $write(a, b_2)$ from $s_2$, you need to prove that there won't be any collision when you encrypt $b_2$ with a newly generated key. It is the same key that is generated in $write(a, b_1)$, since the oracles are the same.
		
		Success of first execution gives you the fact that there is no collision when you encrypt $b_1$. However, there is no way to prove from the stated fact that there won't be a collision when you encrypt $b_2$. This will prevent you from proving the desired property.\\
		
		{\bf I currently have no solution to this. I will keep thinking and keep you updated about it. If anything comes to your mind, please let me know.}\\
		 
		{\color{red} \bf Nickolai:} Thanks, I think the problem makes more sense now.
		In terms of how to solve it..  What about putting the ciphertext into the oracle when encrypt is invoked?
		What I mean is..  When the application calls encrypt(), you choose a ciphertext non-deterministically (i.e., through the oracle).  This gives you the freedom to, in the proof, manipulate the ciphertext chosen for any particular encryption.
		If you had this degree of freedom, then, when proving this case, you could demonstrate a second execution by showing another choice of encrypted result in the other oracle, so that the execution of the recovery code goes down the same path.
		That is, if in execution 1 you saw encrypt(k1, b1) = encrypt(k2, b2), then you can make it also be equal in execution 2.
		And similarly if you saw the two encryptions be non-equal in execution 1, you can make them be non-equal in execution 2.
		The only constraint on this new oracle feature is that you can't choose colliding ciphertexts.
		This means that, to give you this necessary degree of freedom, you have to choose fresh keys often enough so that you're never constrained too much by prior encryptions.\\
		
		{\color{blue} \bf Atalay:} This may not work due to following problem.
		
		Framework requires oracles to be independent of the confidential data. This means you should be able to execute $write(a, b_1)$ from $s_1$, and $write(a, b_2)$ from $s_2$ with the same oracle. If oracle supplies the fresh key and the ciphertext, then it will be encrypt(k, b1) = encrypt(k, b2). Only way this being true is that, somehow, encrypt function of $s_1$ is different than one in $s_2$. I am not entirely sure what this entails and can this difference be a source of leakage.
		
		
		
		
\newpage
\section{Evaluation}
        \subsection{Are specs reasonable?}
	\subsection{Did we achieve the goal?}
	\subsection{How much work did it take?}
	\subsection{What is the performance of the file system?}

\section{Conclusion}

\end{document}
