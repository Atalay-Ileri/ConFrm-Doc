\documentclass[onecolumn]{paper}
\usepackage{tabularx}
\usepackage{color}
\usepackage{listings}
\usepackage{verbatim}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}

\title{ConFrm: Confidentiality Framework for Crash Safe Storage Systems}
\author{Atalay Mert Ileri \and Frans Kaashoek \and Nickolai Zeldovich}
\begin{document}
\maketitle

\subsection*{Introduction}
Absence of bugs were and still are the main focus of formal verification. Many proof techniques and frameworks exist to ensure programs are functionally correctâ€“they do what they are supposed to do. Yet, the opposite is also equally important, as programs should not function in ways they are not meant to. Due to the widespread usage of open source and collaborative software projects, this requirement is more important than ever. It can take only a single malicious program to compromise the integrity of an entire system. 

Though the significance of this notion is indisputable, it is often disregarded by users. Users assume developers act in good faith, but a single ill-intentioned developer {\color{red}(is there another word you could use here?)} could induce a catastrophic effect on a multitude of systems.

Despite its importance, this notion of safety received much less attention from research community. Some works on this area include [citations here]. Most of these studies work with strict information flow policies that do not allow discretionary access control. DISKSEC uses a relaxed notion that allows disclosure of certain data and metadata. Unfortunately, it has serious limitations that include weaker guarantees for nondeterministic executions, as well as the inability to handle confidential data based control flow. 

These works also do not provide clear abstraction layers that enable modularity while preserving safety. (*I need to verify this. It is a bold claim. Can extend on this if it is true. *) 

Our proposed solution to above problems is ConFrm, a framework for implementing and proving the confidentiality of storage systems in a modular fashion. ConFrm facilitates a noninterference definition with better guarantees for nondeterministic behavior, and provides the required tools and necessary conditions for safety preserving abstractions. These two components of ConFrm enable us to overcome the limitations of previous works and provide a simple yet powerful tool for implementing safe storage systems. 

To test the capabilities of ConFrm, we implemented ConFS, a confidential file system that is crash resistant via checksum logging, transactional operations and coarse-grained discretionary access control. 

Both ConFrm and ConFS are implemented in Coq. Proofs are fully machine checked to ensure their correctness. 



%Nickolai: a good starting point might be to articulate what problem you are trying to solve and what your approach / design for addressing that problem looks like.  so, something along the lines of the goal and design sections.

\subsection*{Problems and Motivation}
\paragraph{Unsafety from Frequency}
We are trying to tackle two problems in this work. First issue is the interaction between nondeterminism and noninterference. More specifically, standard noninterference definition fail to address leakages that resulted from different frequencies of possible execution traces of the same program. A simple example of this weakness can be seen below: 


\begin{lstlisting}
if (random_bit() == 1)
  return secret_bit
else
  return random_bit()
\end{lstlisting}

This code leaks the secret bit 50\% of the time and outputs a random bit 50\% of the time. Although the above program satisfies the NI definition, the secret bit can be determined via the observed frequency of repeated calls. \\

\begin{tabular}{| c | c | c |}
	\hline
	Secret bit & Output 0 \% & Output 1 \% \\
	\hline
	0 &	75\% & 25\% \\
	\hline
	1 &	25\% & 75\% \\
	\hline
\end{tabular}\\
 
\paragraph{Unsafe Primitives}
The second problem observed involves using potentially unsafe primitives in implementation. Many storage systems process the data provided to them before storing it, which sometimes includes making decisions based on the contents of the data. A potentially malicious developer can take advantage of this capability to leak information. 

One classic example of this is data deduplication. Deduplication requires branching on confidential data, which can be abused if not handled carefully. One instance we can use to illustrate this point is:


\begin{lstlisting}
write_to_txn(v)
  if (v in txn)
    return false
  else
    add_to_txn(v)
    return true
\end{lstlisting}

This implementation allows an adversary to query the contents of the transaction. Although it may be appealing to prohibit such behaviors to ensure the code is safe, it is a very constraining approach which eliminates many possible efficient implementations. An ideal solution may involve figuring out a method to restrict unsafe utilization. 

It is still possible to deduplicate safely by performing the process after the  transaction is finalized but before committing it. Such a deferred deduplication will still branch on confidential data without revealing it.


\paragraph{Scalability}
We aim to solve above problems while providing scalability. Any technique that will be used in large scale projects is required to support modularity, compositionality, expressive power, and interoperability with other techniques. Provided solution should not constrain developers to a certain proof technique for proving safety, as well as allow them to model systems they are working on to the desired level of detail. 

\subsection*{Solution Approach}
To address the problems stated above, we used 3 approaches:\\
- Quantification of nondeterminism via tokens.\\
- Abstraction via layer system.\\
- Property transfer via simulation proofs.

\subsubsection*{Quantification of Nondeterminism}
This approach have two benefits. First and most significant, it enables us to
turn nondeterministic executions into relatively deterministic ones. 
Relatively deterministic execution is defined as an execution trace that is deterministic given a particular sequence of nondeterministic choices.\\

//EXAMPLE\\

This method is implemented via tokens, an inductive data type that is provided to execution relation. Each token represents a particular nondeterministic choice (e. g. should execution continue or crash?). In some particular cases, they even act like wrappers for a list of tokens themselves. In other words, a token is a unit of nondeterminism that is required to execute a single step.\\

//EXAMPLE\\

With this modified definition, we managed to state and prove a stronger version of noninterference: relatively deterministic noninterference (RDNI). RDNI requires that for any sequence of nondeterministic choices, if there is a completed execution of a program from a state, there exists another execution of the same program* from a related state with same choice sequence. Our definition is termination sensitive.

RDNI's requirement for matching execution from any choice sequence ensures that no matter which nondeterministic branch is followed during the execution, there will be an indistinguishable execution from an equivalent state. This one-to-one correspondence implies that a state cannot be distinguished based on repeated observation of the system.

Another benefit of quantification is that it allows us to weaken the requirements for NI preserving refinements. It is known that a bisimulation between implementation and abstraction is necessary for preserving NI if execution is nondeterministic. Relative determinism enables us to relax this requirement into a simulation with extra properties. \\

//Explanatory image here\\

One critical facet of this alteration is that it permits stronger abstractions that would not be feasible under bisimulations, allowing developers to keep visible only the crucial details of a system, while concealing the ones that are implementation specific.\\

//Example

\subsubsection*{Abstraction via layer system}
Abstraction is a useful tool when dealing with large and complex software systems.
It allows developers to hide implementation details of different modules of a software and purely think in terms of its observed behavior.

Our layer system streamlines the abstraction of implementations by providing tools that makes defining a new DSL that exhibits the same behavior with the implementation easier.
This is crucial in hiding the details of functions that use potentially unsafe primitives in a noninterfering fashion.\\

//Example\\

Once an implementation is abstracted away with a layer, it becomes completely opaque to the rest of the system. Our system guarantees that an implementation that simulates a noninterfering layer is also noninterfering.

Because the operations and state of a layer description are simpler than its underlying implementation, proving their noninterference becomes less complex as well. Additionally, implementations under the layer can be changed without affecting other proofs in the system.

Transforming the representation of a system state has the benefit of simplifying how system is modeled. For example, a file system can be abstracted as a partial mapping between file names to file contents. Once properly abstracted, all the underliying complexities (e.g. inodes, log, block allocators etc.) becomes irrelevant to the system's behavior. This allows developers to define and prove simple confidentiality statements over simple representation. For instance, assigning an owner to each file is much more straightforward than designating each inode and data blocks to an owner, and subsequently keeping track of the information through varying stages of operations. This technique may even be impossible if implementation does optimizations that fit multiple owners' data in a single data unit (e.g. a disk block).

\subsubsection*{NI Transfer via Simulation Proofs}
It is known that, in general nondeterministic case, NI is not preserved under simulation, but under bisimulation. This creates a problem for abstraction techniques, which relies on simulation proofs to show the behavior of implementation is a subset of the abstractraction's. Since bisimulation is a stricter requirement than simulation, the amount of details an abstraction can omit is significantly reduced. Furthermore, you cannot introduce any new behavior or remove any existing behavior in an abstraction. (*Explain this better*)

However we show that RDNI is preserved under simulations combined with some auxiliary properties. This relieves proof burden of the developer significantly as well as increases power of abstraction layers. Our layer system makes it possible to construct complex systems as isolated, self contained pieces; just like normal software systems.

%SelfSimulation_Exists is required for termination sensitivity. If a developer don't care about termination sensitivity, then it is not necessary. In that case it needs to use termination insensitive variant of RDNI (SelfSimulation_Weak).



\begin{comment}

\subsection*{System we consider}
We are consider a storage system with a course-grained ownership. smallest data unit will be referred as a data block, Data are accessed with "a handle", which represents a group of data blocks. Each handle has an owner that is allowed to read and write data to it as well as transfer its ownership to another user.

We are also assuming a crash-resistant transactional storage system where every API call is executed atomically. If a crash happens during an API call, then effects of the call either happens completely or doesn't happen at all.

We assume system is running on a disk with asynchronious buffered writes. Until an explicit sync operation is performeds, it is not guaranteed writes to be persisted on the disk. Ones that are persisted also could be out of order.

\subsection*{Running example}
Throughout the paper, we will follow the scenario where a user writes some data to a file and then transfers ownership of the file to another user.
\begin{lstlisting}
append_and_transfer(handle, data, new_owner)
  extend(handle, data)
  change_owner(handle, new_owner)
\end{lstlisting}
Example is simple enough to not have any distracting details but complex enough to reveal subtleties involved in a possibly malicious storage system implementation.\\

Possible problems that can arise in implementation of write:

- System can stash away the input confidential data. 
(Same as reading the file and stashing it somewhere?)

- System can write data to someone else's file

- System can leak data due to its crash-resistance mechanisms.\\

Possible problems that can arise in implementation of change\_owner:

- System can give ownership to someone else,

- System can write some confidential data belonging to the current user 
to the file before transferring it to new owner.

- System can read file's content then reveal it some other time.\\

If we generalize these problems we can have following general groups:

- Hiding confidential data in a place that gets abstracted away.
This place will be referred as "the stash" and the action of hiding data there as "stashing". This data either can be the new data that is provided to the system as an input to an API call or already existing data that is read by the system during an API call.

- Transferring an existing data to another user. This could be the stashed or already on-disk data.

- Revealing data contents via different crash-and-recovery outcomes.

\end{comment}


%Just like functionality of systems can be precisely defined in terms of specifications, desired properties of those systems can be precisely defined in terms of system properties. A class of these properties that encompasses security and liveness is called hyperproperties. Unlike properties that depends on single run of a system, hyperproperties relate multiple runs of a system. Because of this distinction, hyperproperties of a system are harder to prove and are not preserved under simulation based refinement. A strong notion of simulation called bisimulation is required to preserve hyperproperties. However bisimulation requirement reduces the power of abstraction significantly.

%This poses a challenge to the modular approaches to proving hyperproperties. Since simulation is a core technique to modularly proving an implementation behaving similar to an abstract representation.\\

%//Example here\\


\end{document}
